2018-12-02 17:07:13 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: Renren)
2018-12-02 17:07:13 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.5.2 (default, Nov 12 2018, 13:43:14) - [GCC 5.4.0 20160609], pyOpenSSL 18.0.0 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 2.3, Platform Linux-4.4.0-31-generic-x86_64-with-Ubuntu-16.04-xenial
2018-12-02 17:07:13 [scrapy.crawler] INFO: Overridden settings: {'SPIDER_MODULES': ['Renren.spiders'], 'NEWSPIDER_MODULE': 'Renren.spiders', 'BOT_NAME': 'Renren', 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; rv:11.0) like Gecko', 'LOG_LEVEL': 'INFO', 'LOG_FILE': 'myspider.log'}
2018-12-02 17:07:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.memusage.MemoryUsage']
2018-12-02 17:07:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-02 17:07:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-02 17:07:13 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-12-02 17:07:13 [scrapy.core.engine] INFO: Spider opened
2018-12-02 17:07:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-02 17:07:13 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-02 17:07:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 726,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 1,
 'downloader/request_method_count/POST': 1,
 'downloader/response_bytes': 3335,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 2, 9, 7, 13, 781817),
 'log_count/INFO': 7,
 'memusage/max': 853114880,
 'memusage/startup': 853114880,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 12, 2, 9, 7, 13, 459892)}
2018-12-02 17:07:13 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-02 17:07:37 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: Renren)
2018-12-02 17:07:37 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.5.2 (default, Nov 12 2018, 13:43:14) - [GCC 5.4.0 20160609], pyOpenSSL 18.0.0 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 2.3, Platform Linux-4.4.0-31-generic-x86_64-with-Ubuntu-16.04-xenial
2018-12-02 17:07:37 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'Renren', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'Renren.spiders', 'SPIDER_MODULES': ['Renren.spiders'], 'LOG_FILE': 'myspider.log', 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; rv:11.0) like Gecko'}
2018-12-02 17:07:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logstats.LogStats']
2018-12-02 17:07:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-02 17:07:37 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-02 17:07:37 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-12-02 17:07:37 [scrapy.core.engine] INFO: Spider opened
2018-12-02 17:07:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-02 17:07:38 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-02 17:07:38 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 726,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 1,
 'downloader/request_method_count/POST': 1,
 'downloader/response_bytes': 3385,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 2, 9, 7, 38, 167369),
 'log_count/INFO': 7,
 'memusage/max': 868749312,
 'memusage/startup': 868749312,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 12, 2, 9, 7, 37, 897245)}
2018-12-02 17:07:38 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-02 17:12:28 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: Renren)
2018-12-02 17:12:28 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.5.2 (default, Nov 12 2018, 13:43:14) - [GCC 5.4.0 20160609], pyOpenSSL 18.0.0 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 2.3, Platform Linux-4.4.0-31-generic-x86_64-with-Ubuntu-16.04-xenial
2018-12-02 17:12:28 [scrapy.crawler] INFO: Overridden settings: {'LOG_LEVEL': 'INFO', 'SPIDER_MODULES': ['Renren.spiders'], 'BOT_NAME': 'Renren', 'LOG_FILE': 'myspider.log', 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; rv:11.0) like Gecko', 'NEWSPIDER_MODULE': 'Renren.spiders'}
2018-12-02 17:12:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage']
2018-12-02 17:12:28 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-02 17:12:28 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-02 17:12:28 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-12-02 17:12:28 [scrapy.core.engine] INFO: Spider opened
2018-12-02 17:12:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-02 17:12:28 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-02 17:12:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 726,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 1,
 'downloader/request_method_count/POST': 1,
 'downloader/response_bytes': 3374,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 2, 9, 12, 28, 879322),
 'log_count/INFO': 7,
 'memusage/max': 928083968,
 'memusage/startup': 928083968,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 12, 2, 9, 12, 28, 483958)}
2018-12-02 17:12:28 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-02 17:20:28 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: Renren)
2018-12-02 17:20:28 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.5.2 (default, Nov 12 2018, 13:43:14) - [GCC 5.4.0 20160609], pyOpenSSL 18.0.0 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 2.3, Platform Linux-4.4.0-31-generic-x86_64-with-Ubuntu-16.04-xenial
2018-12-02 17:20:28 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'Renren.spiders', 'LOG_LEVEL': 'INFO', 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; rv:11.0) like Gecko', 'LOG_FILE': 'myspider.log', 'BOT_NAME': 'Renren', 'SPIDER_MODULES': ['Renren.spiders']}
2018-12-02 17:20:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-02 17:20:28 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-02 17:20:28 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-02 17:20:28 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-12-02 17:20:28 [scrapy.core.engine] INFO: Spider opened
2018-12-02 17:20:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-02 17:20:30 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-02 17:20:30 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1313,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 1,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 3903,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'dupefilter/filtered': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 2, 9, 20, 30, 554740),
 'log_count/INFO': 7,
 'memusage/max': 989319168,
 'memusage/startup': 989319168,
 'request_depth_max': 2,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 12, 2, 9, 20, 28, 885078)}
2018-12-02 17:20:30 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-02 17:21:52 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: Renren)
2018-12-02 17:21:52 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.5.2 (default, Nov 12 2018, 13:43:14) - [GCC 5.4.0 20160609], pyOpenSSL 18.0.0 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 2.3, Platform Linux-4.4.0-31-generic-x86_64-with-Ubuntu-16.04-xenial
2018-12-02 17:21:52 [scrapy.crawler] INFO: Overridden settings: {'SPIDER_MODULES': ['Renren.spiders'], 'LOG_LEVEL': 'INFO', 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; rv:11.0) like Gecko', 'NEWSPIDER_MODULE': 'Renren.spiders', 'LOG_FILE': 'myspider.log', 'BOT_NAME': 'Renren'}
2018-12-02 17:21:52 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole']
2018-12-02 17:21:52 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-02 17:21:52 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-02 17:21:52 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-12-02 17:21:52 [scrapy.core.engine] INFO: Spider opened
2018-12-02 17:21:52 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-02 17:21:54 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-02 17:21:54 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1313,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 1,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 3903,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'dupefilter/filtered': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 2, 9, 21, 54, 75676),
 'log_count/INFO': 7,
 'memusage/max': 991084544,
 'memusage/startup': 991084544,
 'request_depth_max': 2,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 12, 2, 9, 21, 52, 450429)}
2018-12-02 17:21:54 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-02 17:25:29 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: Renren)
2018-12-02 17:25:29 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.5.2 (default, Nov 12 2018, 13:43:14) - [GCC 5.4.0 20160609], pyOpenSSL 18.0.0 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 2.3, Platform Linux-4.4.0-31-generic-x86_64-with-Ubuntu-16.04-xenial
2018-12-02 17:25:29 [scrapy.crawler] INFO: Overridden settings: {'LOG_LEVEL': 'INFO', 'LOG_FILE': 'myspider.log', 'NEWSPIDER_MODULE': 'Renren.spiders', 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; rv:11.0) like Gecko', 'SPIDER_MODULES': ['Renren.spiders'], 'BOT_NAME': 'Renren'}
2018-12-02 17:25:29 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole']
2018-12-02 17:25:29 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-02 17:25:29 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-02 17:25:29 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-12-02 17:25:29 [scrapy.core.engine] INFO: Spider opened
2018-12-02 17:25:29 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-02 17:25:30 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-02 17:25:30 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1313,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 1,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 3903,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'dupefilter/filtered': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 2, 9, 25, 30, 906325),
 'log_count/INFO': 7,
 'memusage/max': 1020653568,
 'memusage/startup': 1020653568,
 'request_depth_max': 2,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 12, 2, 9, 25, 29, 267236)}
2018-12-02 17:25:30 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-02 17:25:49 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: Renren)
2018-12-02 17:25:49 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.5.2 (default, Nov 12 2018, 13:43:14) - [GCC 5.4.0 20160609], pyOpenSSL 18.0.0 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 2.3, Platform Linux-4.4.0-31-generic-x86_64-with-Ubuntu-16.04-xenial
2018-12-02 17:25:49 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'Renren', 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; rv:11.0) like Gecko', 'NEWSPIDER_MODULE': 'Renren.spiders', 'LOG_LEVEL': 'INFO', 'SPIDER_MODULES': ['Renren.spiders'], 'LOG_FILE': 'myspider.log'}
2018-12-02 17:25:50 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole']
2018-12-02 17:25:50 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-02 17:25:50 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-02 17:25:50 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-12-02 17:25:50 [scrapy.core.engine] INFO: Spider opened
2018-12-02 17:25:50 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-02 17:25:51 [scrapy.core.scraper] ERROR: Spider error processing <POST http://qd.pinganedai.vip/website/csct/listSingleChannel> (referer: http://qd.pinganedai.vip/website/main.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/python/Desktop/Renren/Renren/spiders/renren.py", line 48, in parse_page
    register = json.loads(response.body).get('rows')[0].get('reg')
  File "/usr/lib/python3.5/json/__init__.py", line 312, in loads
    s.__class__.__name__))
TypeError: the JSON object must be str, not 'bytes'
2018-12-02 17:25:51 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-02 17:25:51 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1313,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 1,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 3942,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 2, 9, 25, 51, 819446),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'memusage/max': 1021726720,
 'memusage/startup': 1021726720,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2018, 12, 2, 9, 25, 50, 95976)}
2018-12-02 17:25:51 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-02 17:26:34 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: Renren)
2018-12-02 17:26:34 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.5.2 (default, Nov 12 2018, 13:43:14) - [GCC 5.4.0 20160609], pyOpenSSL 18.0.0 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 2.3, Platform Linux-4.4.0-31-generic-x86_64-with-Ubuntu-16.04-xenial
2018-12-02 17:26:34 [scrapy.crawler] INFO: Overridden settings: {'LOG_LEVEL': 'INFO', 'BOT_NAME': 'Renren', 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; rv:11.0) like Gecko', 'SPIDER_MODULES': ['Renren.spiders'], 'LOG_FILE': 'myspider.log', 'NEWSPIDER_MODULE': 'Renren.spiders'}
2018-12-02 17:26:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2018-12-02 17:26:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-02 17:26:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-02 17:26:34 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-12-02 17:26:34 [scrapy.core.engine] INFO: Spider opened
2018-12-02 17:26:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-02 17:26:36 [scrapy.core.scraper] ERROR: Spider error processing <POST http://qd.pinganedai.vip/website/csct/listSingleChannel> (referer: http://qd.pinganedai.vip/website/main.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/python/Desktop/Renren/Renren/spiders/renren.py", line 48, in parse_page
    register = json.loads(response.body).get('rows')[0].get('reg')
  File "/usr/lib/python3.5/json/__init__.py", line 312, in loads
    s.__class__.__name__))
TypeError: the JSON object must be str, not 'bytes'
2018-12-02 17:26:36 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-02 17:26:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1313,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 1,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 3953,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 2, 9, 26, 36, 613109),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'memusage/max': 1022656512,
 'memusage/startup': 1022656512,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2018, 12, 2, 9, 26, 34, 886625)}
2018-12-02 17:26:36 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-02 17:26:53 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: Renren)
2018-12-02 17:26:53 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.5.2 (default, Nov 12 2018, 13:43:14) - [GCC 5.4.0 20160609], pyOpenSSL 18.0.0 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 2.3, Platform Linux-4.4.0-31-generic-x86_64-with-Ubuntu-16.04-xenial
2018-12-02 17:26:53 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'Renren.spiders', 'BOT_NAME': 'Renren', 'LOG_FILE': 'myspider.log', 'LOG_LEVEL': 'INFO', 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; rv:11.0) like Gecko', 'SPIDER_MODULES': ['Renren.spiders']}
2018-12-02 17:26:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.memusage.MemoryUsage']
2018-12-02 17:26:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-02 17:26:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-02 17:26:53 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-12-02 17:26:53 [scrapy.core.engine] INFO: Spider opened
2018-12-02 17:26:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-02 17:26:55 [scrapy.core.scraper] ERROR: Spider error processing <POST http://qd.pinganedai.vip/website/csct/listSingleChannel> (referer: http://qd.pinganedai.vip/website/main.htm)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/python/Desktop/Renren/Renren/spiders/renren.py", line 47, in parse_page
    register = json.loads(response.body).get('rows')[0].get('reg')
  File "/usr/lib/python3.5/json/__init__.py", line 312, in loads
    s.__class__.__name__))
TypeError: the JSON object must be str, not 'bytes'
2018-12-02 17:26:55 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-02 17:26:55 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1313,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 1,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 3903,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 2, 9, 26, 55, 606247),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'memusage/max': 1023234048,
 'memusage/startup': 1023234048,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2018, 12, 2, 9, 26, 53, 863990)}
2018-12-02 17:26:55 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-02 17:27:13 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: Renren)
2018-12-02 17:27:13 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.5.2 (default, Nov 12 2018, 13:43:14) - [GCC 5.4.0 20160609], pyOpenSSL 18.0.0 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 2.3, Platform Linux-4.4.0-31-generic-x86_64-with-Ubuntu-16.04-xenial
2018-12-02 17:27:13 [scrapy.crawler] INFO: Overridden settings: {'SPIDER_MODULES': ['Renren.spiders'], 'BOT_NAME': 'Renren', 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; rv:11.0) like Gecko', 'NEWSPIDER_MODULE': 'Renren.spiders', 'LOG_FILE': 'myspider.log', 'LOG_LEVEL': 'INFO'}
2018-12-02 17:27:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-02 17:27:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-02 17:27:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-02 17:27:13 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-12-02 17:27:13 [scrapy.core.engine] INFO: Spider opened
2018-12-02 17:27:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-02 17:27:15 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-02 17:27:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1313,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 1,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 3942,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 2, 9, 27, 15, 23319),
 'log_count/INFO': 7,
 'memusage/max': 1026158592,
 'memusage/startup': 1026158592,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 12, 2, 9, 27, 13, 353159)}
2018-12-02 17:27:15 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-02 17:27:49 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: Renren)
2018-12-02 17:27:49 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.5.2 (default, Nov 12 2018, 13:43:14) - [GCC 5.4.0 20160609], pyOpenSSL 18.0.0 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 2.3, Platform Linux-4.4.0-31-generic-x86_64-with-Ubuntu-16.04-xenial
2018-12-02 17:27:49 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'Renren.spiders', 'BOT_NAME': 'Renren', 'SPIDER_MODULES': ['Renren.spiders'], 'LOG_LEVEL': 'INFO', 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; rv:11.0) like Gecko', 'LOG_FILE': 'myspider.log'}
2018-12-02 17:27:49 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-12-02 17:27:49 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-02 17:27:49 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-02 17:27:49 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-12-02 17:27:49 [scrapy.core.engine] INFO: Spider opened
2018-12-02 17:27:49 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-02 17:27:49 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/engine.py", line 127, in _next_request
    request = next(slot.start_requests)
  File "/home/python/Desktop/Renren/Renren/spiders/renren.py", line 24, in start_requests
    yield scrapy.FormRequest(post_url, formdata=formdata, headers=headers, callback=self.parse)
NameError: name 'headers' is not defined
2018-12-02 17:27:49 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-02 17:27:49 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 2, 9, 27, 49, 364383),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'memusage/max': 1026764800,
 'memusage/startup': 1026764800,
 'start_time': datetime.datetime(2018, 12, 2, 9, 27, 49, 357740)}
2018-12-02 17:27:49 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-02 17:27:54 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: Renren)
2018-12-02 17:27:54 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.5.2 (default, Nov 12 2018, 13:43:14) - [GCC 5.4.0 20160609], pyOpenSSL 18.0.0 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 2.3, Platform Linux-4.4.0-31-generic-x86_64-with-Ubuntu-16.04-xenial
2018-12-02 17:27:54 [scrapy.crawler] INFO: Overridden settings: {'LOG_LEVEL': 'INFO', 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; rv:11.0) like Gecko', 'SPIDER_MODULES': ['Renren.spiders'], 'BOT_NAME': 'Renren', 'NEWSPIDER_MODULE': 'Renren.spiders', 'LOG_FILE': 'myspider.log'}
2018-12-02 17:27:54 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.memusage.MemoryUsage']
2018-12-02 17:27:54 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-02 17:27:54 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-02 17:27:54 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-12-02 17:27:54 [scrapy.core.engine] INFO: Spider opened
2018-12-02 17:27:54 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-02 17:27:54 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/scrapy/core/engine.py", line 127, in _next_request
    request = next(slot.start_requests)
  File "/home/python/Desktop/Renren/Renren/spiders/renren.py", line 24, in start_requests
    yield scrapy.FormRequest(post_url, formdata=formdata, headers=headers, callback=self.parse)
NameError: name 'headers' is not defined
2018-12-02 17:27:54 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-02 17:27:54 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 2, 9, 27, 54, 400333),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'memusage/max': 1026912256,
 'memusage/startup': 1026912256,
 'start_time': datetime.datetime(2018, 12, 2, 9, 27, 54, 393594)}
2018-12-02 17:27:54 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-02 17:42:16 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: Renren)
2018-12-02 17:42:16 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.5.2 (default, Nov 12 2018, 13:43:14) - [GCC 5.4.0 20160609], pyOpenSSL 18.0.0 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 2.3, Platform Linux-4.4.0-31-generic-x86_64-with-Ubuntu-16.04-xenial
2018-12-02 17:42:16 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'Renren', 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; rv:11.0) like Gecko', 'LOG_FILE': 'myspider.log', 'NEWSPIDER_MODULE': 'Renren.spiders', 'LOG_LEVEL': 'INFO', 'SPIDER_MODULES': ['Renren.spiders']}
2018-12-02 17:42:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole']
2018-12-02 17:42:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-02 17:42:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-02 17:42:16 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-12-02 17:42:16 [scrapy.core.engine] INFO: Spider opened
2018-12-02 17:42:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-02 17:42:17 [scrapy.core.downloader.tls] WARNING: Remote certificate is not valid for hostname "saas.fin-tech.cn"; '*.fin-tech.cn'!='saas.fin-tech.cn'
2018-12-02 17:42:18 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-02 17:42:18 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1727,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 1,
 'downloader/request_method_count/POST': 3,
 'downloader/response_bytes': 5903,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 3,
 'downloader/response_status_count/302': 1,
 'dupefilter/filtered': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 2, 9, 42, 18, 556270),
 'log_count/INFO': 7,
 'log_count/WARNING': 1,
 'memusage/max': 1036251136,
 'memusage/startup': 1036251136,
 'request_depth_max': 1,
 'response_received_count': 3,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'start_time': datetime.datetime(2018, 12, 2, 9, 42, 16, 867349)}
2018-12-02 17:42:18 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-02 18:03:52 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: Renren)
2018-12-02 18:03:52 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.5.2 (default, Nov 12 2018, 13:43:14) - [GCC 5.4.0 20160609], pyOpenSSL 18.0.0 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 2.3, Platform Linux-4.4.0-31-generic-x86_64-with-Ubuntu-16.04-xenial
2018-12-02 18:03:52 [scrapy.crawler] INFO: Overridden settings: {'LOG_FILE': 'myspider.log', 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; rv:11.0) like Gecko', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'Renren.spiders', 'BOT_NAME': 'Renren', 'SPIDER_MODULES': ['Renren.spiders']}
2018-12-02 18:03:52 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logstats.LogStats']
2018-12-02 18:03:52 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-02 18:03:52 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-02 18:03:52 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-12-02 18:03:52 [scrapy.core.engine] INFO: Spider opened
2018-12-02 18:03:52 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-02 18:03:53 [scrapy.core.downloader.tls] WARNING: Remote certificate is not valid for hostname "saas.fin-tech.cn"; '*.fin-tech.cn'!='saas.fin-tech.cn'
2018-12-02 18:03:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://saas.fin-tech.cn/admin/index.php/linkshare/index/share_count_ajax.html?page=1&limit=10&search_date_start=2018-12-01&search_date_end=2018-12-01> (referer: https://saas.fin-tech.cn/admin/index.php?g=linkshare&m=index)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/python/Desktop/Renren/Renren/spiders/renren.py", line 60, in parse_page
    register = json.loads(response.body.decode()).get('rows')[0].get('reg')
TypeError: 'NoneType' object is not subscriptable
2018-12-02 18:03:54 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-02 18:03:54 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2302,
 'downloader/request_count': 5,
 'downloader/request_method_count/GET': 2,
 'downloader/request_method_count/POST': 3,
 'downloader/response_bytes': 6248,
 'downloader/response_count': 5,
 'downloader/response_status_count/200': 4,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 2, 10, 3, 54, 594105),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'log_count/WARNING': 1,
 'memusage/max': 1060184064,
 'memusage/startup': 1060184064,
 'request_depth_max': 1,
 'response_received_count': 4,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2018, 12, 2, 10, 3, 52, 918641)}
2018-12-02 18:03:54 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-02 18:04:55 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: Renren)
2018-12-02 18:04:55 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.5.2 (default, Nov 12 2018, 13:43:14) - [GCC 5.4.0 20160609], pyOpenSSL 18.0.0 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 2.3, Platform Linux-4.4.0-31-generic-x86_64-with-Ubuntu-16.04-xenial
2018-12-02 18:04:55 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'Renren', 'SPIDER_MODULES': ['Renren.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; rv:11.0) like Gecko', 'NEWSPIDER_MODULE': 'Renren.spiders', 'LOG_FILE': 'myspider.log', 'LOG_LEVEL': 'INFO'}
2018-12-02 18:04:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logstats.LogStats']
2018-12-02 18:04:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-02 18:04:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-02 18:04:55 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-12-02 18:04:55 [scrapy.core.engine] INFO: Spider opened
2018-12-02 18:04:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-02 18:04:55 [scrapy.core.downloader.tls] WARNING: Remote certificate is not valid for hostname "saas.fin-tech.cn"; '*.fin-tech.cn'!='saas.fin-tech.cn'
2018-12-02 18:04:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://saas.fin-tech.cn/admin/index.php/linkshare/index/share_count_ajax.html?page=1&limit=10&search_date_start=2018-12-01&search_date_end=2018-12-01> (referer: https://saas.fin-tech.cn/admin/index.php?g=linkshare&m=index)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/python/Desktop/Renren/Renren/spiders/renren.py", line 63, in parse_page
    register = json.loads(response.body.decode()).get('rows')[0].get('reg')
TypeError: 'NoneType' object is not subscriptable
2018-12-02 18:04:57 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-02 18:04:57 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2302,
 'downloader/request_count': 5,
 'downloader/request_method_count/GET': 2,
 'downloader/request_method_count/POST': 3,
 'downloader/response_bytes': 6287,
 'downloader/response_count': 5,
 'downloader/response_status_count/200': 4,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 2, 10, 4, 57, 18079),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'log_count/WARNING': 1,
 'memusage/max': 1066975232,
 'memusage/startup': 1066975232,
 'request_depth_max': 1,
 'response_received_count': 4,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2018, 12, 2, 10, 4, 55, 185682)}
2018-12-02 18:04:57 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-02 18:08:04 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: Renren)
2018-12-02 18:08:04 [scrapy.utils.log] INFO: Versions: lxml 3.5.0.0, libxml2 2.9.3, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.5.2 (default, Nov 12 2018, 13:43:14) - [GCC 5.4.0 20160609], pyOpenSSL 18.0.0 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 2.3, Platform Linux-4.4.0-31-generic-x86_64-with-Ubuntu-16.04-xenial
2018-12-02 18:08:04 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; rv:11.0) like Gecko', 'LOG_LEVEL': 'INFO', 'LOG_FILE': 'myspider.log', 'NEWSPIDER_MODULE': 'Renren.spiders', 'BOT_NAME': 'Renren', 'SPIDER_MODULES': ['Renren.spiders']}
2018-12-02 18:08:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2018-12-02 18:08:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-02 18:08:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-02 18:08:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-12-02 18:08:04 [scrapy.core.engine] INFO: Spider opened
2018-12-02 18:08:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-02 18:08:05 [scrapy.core.downloader.tls] WARNING: Remote certificate is not valid for hostname "saas.fin-tech.cn"; '*.fin-tech.cn'!='saas.fin-tech.cn'
2018-12-02 18:08:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://saas.fin-tech.cn/admin/index.php/linkshare/index/share_count_ajax.html?page=1&limit=10&search_date_start=2018-12-01&search_date_end=2018-12-01> (referer: https://saas.fin-tech.cn/admin/index.php?g=linkshare&m=index)
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/python/Desktop/Renren/Renren/spiders/renren.py", line 64, in parse_page
    register = json.loads(response.body.decode()).get('rows')[0].get('reg')
TypeError: 'NoneType' object is not subscriptable
2018-12-02 18:08:06 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-02 18:08:06 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2302,
 'downloader/request_count': 5,
 'downloader/request_method_count/GET': 2,
 'downloader/request_method_count/POST': 3,
 'downloader/response_bytes': 6248,
 'downloader/response_count': 5,
 'downloader/response_status_count/200': 4,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 2, 10, 8, 6, 514985),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'log_count/WARNING': 1,
 'memusage/max': 1069600768,
 'memusage/startup': 1069600768,
 'request_depth_max': 1,
 'response_received_count': 4,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2018, 12, 2, 10, 8, 4, 863303)}
2018-12-02 18:08:06 [scrapy.core.engine] INFO: Spider closed (finished)
